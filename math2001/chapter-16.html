<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />

    <title>MATH2001/7000 - Chapter 16</title>

    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />

    <link rel="stylesheet" href="revealjs/dist/reveal.css">
	<link rel="stylesheet" href="revealjs/dist/theme/white.css" id="theme">
	<link rel="stylesheet" href="revealjs/third-party-plugin/chalkboard/style.css">
	<link rel="stylesheet" href="revealjs/third-party-plugin/customcontrols/style.css">

	<link rel="stylesheet" href="mySetup/mylayout.css" />

	<!-- Code syntax highlighting https://revealjs.com/-->
	<link rel="stylesheet" href="revealjs/plugin/highlight/zenburn.css">

	<link rel="icon" type="image/png" href="images/icon/infinity32.png" sizes="32x32">
	<link rel="icon" type="image/png" href="images/icon/infinity16.png" sizes="16x16">

	<!-- Printing and PDF exports -->
	<script>
		var link = document.createElement('link');
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match(/print-pdf/gi) ? 'export/pdf.css' :
			'export/paper.css';
		document.getElementsByTagName('head')[0].appendChild(link);
	</script>


	<!-- This script is to display Github buttons -->
	<script async defer src="mySetup/buttons.js"></script>

	<!--[if lt IE 9]>
		<script src="../reveal.js/lib/js/html5shiv.js"></script>
		<![endif]-->

	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-JPYTNF6MB4"></script>
	<script src="mySetup/google-analytics-ga4.js"></script>
  

  </head>

  <body>
    <div class="reveal">
      <div class="slides">
        <!-- Any section element inside of this container is displayed as a slide -->

        <section>
          <h2>Calculus & <br />Linear Algebra II</h2>
          <p>Chapter 16</p>
        </section>

        <section>
          <section data-auto-animate>
            <h3>16 Diagonalisation</h3>
            <div class="left-txt size-85">
              <p>
                By the end of this section, you should be able to answer the
                following questions:
              </p>
              <ul>
                <li class="fragment" data-fragment-index="0">
                  How do you find a matrix $P$ which diagonalises a given matrix
                  $A$?
                </li>
                <li class="fragment" data-fragment-index="1">
                  How do you determine if $A$ is diagonalisable?
                </li>
                <li class="fragment" data-fragment-index="2">
                  What are two applications of diagonalisation?
                </li>
              </ul>
            </div>
            <br /><br /><br />
          </section>

          <section data-auto-animate>
            <h3>16 Diagonalisation</h3>
            <div class="size-80">
              <div class="left-txt">
                <p>
                  A square matrix $A$ is <em>diagonalisable</em> if there is a
                  non-singular matrix $P$ such that $P^{-1}AP$ is a diagonal
                  matrix.
                  <span class="fragment" data-fragment-index="0">
                    Here we consider the question: given a matrix, is it
                    diagonalisable?
                  </span>
                  <span class="fragment" data-fragment-index="1">
                    If so, how do we find $P$?
                  </span>
                </p>
                <p class="fragment" data-fragment-index="2">
                  The secret to constructing such a $P$ is to let the columns of
                  $P$ be the eigenvectors of $A$.
                  <span class="fragment" data-fragment-index="3">
                    We immediately have that $AP=PD$, where $D$ is a diagonal
                    matrix with eigenvalues on the diagonal.
                  </span>
                  <span class="fragment" data-fragment-index="4">
                    We know from <a href="chapter-15.html#/equivalent-statements/4">section 15.1</a>
                    that $P$ is invertible if and only if the columns of $P$ are
                    linearly independent.
                  </span>
                </p>
              </div>
            </div><br/><br/>
          </section>

          <section data-auto-animate>
            <h3>16 Diagonalisation</h3>
            <div class="size-80">
              <div class="left-txt">
                <p>
                  Hence, we have the following result:
                </p>
                <p>
                  The $n\times n$ matrix $A$ is diagonalisable if and only if
                  $A$ has $n$ linearly independent eigenvectors.
                </p>
                <p>
                  <span class="fragment" data-fragment-index="0">Is the matrix</span>
                </p>
              </div>
              <div>
                <p>
                 <span class="fragment" data-fragment-index="0"> $A=\left(\begin{array}{rrr}-3&1&0\\1&-2&1\\0&1&-3\end{array}\right)$</span>
                </p>
              </div>
              <div class="left-txt">
                <p>
                  <span class="fragment" data-fragment-index="0"> diagonalisable?</span>
                 
                </p>
              </div>
            </div>
            <br /><br /><br /><br/>
          </section>

          <section data-auto-animate>
            <h5>16 Diagonalisation</h5>
            <div class="size-80">
              <div class="left-txt">
                
                <p>
                  This matrix has eigenvalues $-3, -1, -4,$
                  <span class="fragment" data-fragment-index="1">
                    with corresponding eigenvectors
                  </span>
                </p>
              </div>
              <div>
                <p class="fragment" data-fragment-index="1">
                  $\v_1=\mat{r}{1\\0\\-1},\;$ $\;\v_2=\mat{c}{1\\2\\1},\;$
                  $\;\v_3=\mat{r}{1\\-1\\1}$.
                </p>
              </div>
              <div class="left-txt">
                <p class="fragment" data-fragment-index="2">
                  We form the matrix $$ P=\left(\begin{array}{rrr}1&1&1\\0&\;
                  2&-1\\-1&1&1\end{array}\right) $$ whose columns are these
                  eigenvectors.
                </p>
              </div>
            </div>

            <div style=" position:absolute;bottom:50px;right:-50px;font-size:60%;color:rgb(100,100,100);" >
              <p>$A=\left(\begin{array}{rrr}-3&1&0\\1&-2&1\\0&1&-3\end{array}\right)$</p>
            </div>
            <br />
          </section>

          <section data-auto-animate>
            <h5>16 Diagonalisation</h5>

            <div  style="font-size:70%;color:rgb(100,100,100);">
              <p> $A=\left(\begin{array}{rrr}-3&1&0\\1&-2&1\\0&1&-3\end{array}\right)$</p>
            </div>

            <div class="size-80">
              
              <div class="left-txt">
                
                <p>
                  We can check directly that $P^{-1}AP=D,$
                  <span class="fragment" data-fragment-index="0">
                    where
                    $$\left(\begin{array}{rrr}-3&0&0\\0&-1&0\\0&0&-4\end{array}\right)=D$$
                  </span>
                  <span class="fragment" data-fragment-index="0">
                    is a diagonal matrix with the eigenvalues on the diagonal.
                  </span>
                </p>
              </div>
            </div>
            <br /><br /><br /><br/>
          </section>

          <section data-auto-animate>
            <h3>16 Diagonalisation</h3>
            <div class="size-80">
              <div class="left-txt">
                <p>
                  So steps for diagonalising an $n\times n$ matrix $A$:
                </p>
                <ol style="line-height: 20px;margin-bottom:10px">
                  <li class="fragment" data-fragment-index="0" style=" margin-bottom: 30px; ">
                    Find eigenvalues $\lambda_1, \lambda_2, \cdots$, and the
                    corresponding eigenvectors $\v_1, \v_2, \cdots$, of $A$.
                  </li>
                  <li class="fragment" data-fragment-index="1" style=" margin-bottom: 30px; ">
                    Check if $A$ has $n$ linearly independent eigenvectors.
                  </li>
                  <li class="fragment" data-fragment-index="2" style=" margin-bottom: 30px; ">
                    If no, $A$ is not diagonalizable. <br />
                    <span class="fragment" data-fragment-index="3">
                      If yes, $A$ is diagonalizable. 
                    </span>
                    <span class="fragment" data-fragment-index="4">
                      In this case, form matrix
                      $P=(\v_1|\v_2|\cdots|\v_n)$.
                    </span>
                    <span class="fragment" data-fragment-index="5">
                       Then $P^{-1}$ exists and $P$
                      diagonalizes $A$, i.e. $P^{-1}AP=diag\{\lambda_1, \cdots,
                      \lambda_n\}$.
                    </span>
                  </li>
                </ol>
              </div>
            </div>
            <br /><br />
          </section>
        </section>

        <section>
          <section data-auto-animate>
            <h4>16.1 Similar matrices</h4>
            <div class="size-80">
              <div class="left-txt">
                <p>
                  <span class="fragment" data-fragment-index="0">
                    Two matrices $A$ and $B$ are <em>similar</em> if there is a
                    non-singular matrix $P$ such that $B=P^{-1}AP$.
                  </span>
                </p>
                <p class="fragment" data-fragment-index="1">
                  The statements "$A$ is diagonalisable" and "$A$ is similar to
                  a diagonal matrix" are equivalent.
                </p>
                <p class="fragment" data-fragment-index="2">
                  <strong>
                    16.1.1 Theorem (similar matrices)
                  </strong>
                </p>
                <p class="fragment" data-fragment-index="3">
                  Similar matrices have the same eigenvalues.
                </p>
              </div>
            </div>
            <br /><br /><br/>
          </section>
          <section data-auto-animate>
            <h4>16.1 Similar matrices</h4>
            <div class="size-80">
              <div class="left-txt">
                <p>
                  <strong>
                    16.1.1 Theorem (similar matrices)
                  </strong>
                </p>
                <p>
                  Similar matrices have the same eigenvalues.
                </p>
                <p>
                  In fact, if $B=P^{-1}AP$ and $\v$ is an eigenvector of
                  $A$ corresponding to eigenvalue $\lambda$,
                  <span class="fragment" data-fragment-index="0">
                    then $P^{-1}\v$ is an eigenvector of $B$ corresponding
                    to eigenvalue $\lambda$.
                  </span>
                  <span class="fragment" data-fragment-index="1">
                    This is because
                  </span>
                </p>
                <table id="eqarray">
                  <tr class="fragment" data-fragment-index="1">
                    <td>
                      $B\left(P^{-1}\v\right)$
                    </td>
                    <td>
                      $=$
                    </td>
                    <td>
                      $\left(P^{-1}AP\right)P^{-1}\v$
                    </td>
                  </tr>
                  <tr class="fragment" data-fragment-index="2">
                    <td></td>
                    <td>
                      $=$
                    </td>
                    <td>
                      $ P^{-1}\left(A\v\right)$
                    </td>
                  </tr>
                  <tr class="fragment" data-fragment-index="3">
                    <td></td>
                    <td>
                      $=$
                    </td>
                    <td>
                      $P^{-1}\left(\lambda \v\right)$
                    </td>
                  </tr>
                  <tr class="fragment" data-fragment-index="4">
                    <td></td>
                    <td>
                      $=$
                    </td>
                    <td>
                      $\lambda \left(P^{-1}\v\right)$
                    </td>
                  </tr>
                </table>
              </div>
            </div>
            <br />
          </section>
        </section>

        <section>
          <section data-auto-animate>
            <h4>16.2 A closer look at the diagonal matrix</h4>
            <div class="size-70">
              <div class="left-txt">
                <p>
                  <span class="fragment" data-fragment-index="0">
                    Let the matrix $A$ be $n\times n$ with $n$ linearly
                    independent eigenvectors $\v_1,\dots, \v_n$
                    corresponding to eigenvalues $\lambda_1,\dots,\lambda_n$.
                  </span>
                  <span class="fragment" data-fragment-index="1">
                    Let $$ P=(\v_1| \dots |\v_n) $$ be the $n\times
                    n$ matrix whose columns are the eigenvectors.
                  </span>
                  <span class="fragment" data-fragment-index="2">
                    Then $$ P^{-1}AP=\left(\begin{array}{cccc}
                    \lambda_1&0&\cdots&0\\0&\lambda_2&\cdots&0\\\vdots&\vdots&\ddots&\vdots\\
                    0&0&\cdots&\lambda_n\end{array}\right), $$ the diagonal
                    matrix with the eigenvalues down the main diagonal.
                  </span>
                  
                </p>
              </div>
            </div>
            <br/>
          </section>
          <section data-auto-animate>
            <h4>16.2 A closer look at the diagonal matrix</h4>
            <div class="size-50">
              <div class="left-txt">
                <p>
                  <span>
                    Let the matrix $A$ be $n\times n$ with $n$ linearly
                    independent eigenvectors $\v_1,\dots, \v_n$
                    corresponding to eigenvalues $\lambda_1,\dots,\lambda_n$.
                  </span>
                  <span>
                    Let $$ P=(\v_1| \dots |\v_n) $$ be the $n\times
                    n$ matrix whose columns are the eigenvectors.
                  </span>
                  <span>
                    Then $$ P^{-1}AP=\left(\begin{array}{cccc}
                    \lambda_1&0&\cdots&0\\0&\lambda_2&\cdots&0\\\vdots&\vdots&\ddots&\vdots\\
                    0&0&\cdots&\lambda_n\end{array}\right), $$ the diagonal
                    matrix with the eigenvalues down the main diagonal.
                  </span>
                </p>
              </div>
            </div>
            <div class="size-70">
              <div class="left-txt">
                  <span>
                    The important point here is the order in which the
                    eigenvalues appear.
                  </span>
                  <span class="fragment" data-fragment-index="0">
					They correspond to the
					order in which the associated eigenvectors 
					appear in the columns of $P$.
                  </span>
                </p>
              </div>
            </div>
			<br/>
          </section>
        </section>

		<section>
 
			<section data-auto-animate>
				<h4>16.3 Diagonalisability</h4>
				<div class="size-80">
					<div class="left-txt">
						<p>
							<span class="fragment" data-fragment-index="0">
								We know that an $n\times n$ matrix $A$ is 
								diagonalisable 
								if and only if $A$ has $n$ linearly 
								 independent eigenvectors.
							</span>
						</p>
						<p class="fragment" data-fragment-index="1">
							Now say $\lambda_1,\dots,\lambda_m$ are 
							<em>distinct</em> eigenvalues of $A$, 
							with corresponding eigenvectors $\v_1,\dots,\v_m$.
							<span>
								Then we have also seen that 
								$\v_1,\dots,\v_m$ 
								are linearly independent.
							</span>
						</p>
						<p class="fragment" data-fragment-index="2">
							Hence if $A$ is $n\times n$ with $n$ 
							distinct eigenvalues, then $A$ is diagonalisable. 
						</p>
						<p class="fragment" data-fragment-index="3">
							The question remains, if $A$ has 
							fewer than $n$ distinct eigenvalues, how do we 
							know if $A$ is diagonalisable? 
						</p>
					</div>
				</div>
        <br/><br/>
			</section>

			<section data-auto-animate>
				<h5>16.3.1 Example</h5>
				<div class="size-80">
					<div class="left-txt">
						<p>
							<span>
								Let $A=\left(\begin{array}{ccc}2&1&3\\0&1&0\\0&0&1\end{array}\right)$
                and $B=\left(\begin{array}{ccc}2&1&3\\0&1&1\\0&0&1\end{array}\right)$.
							</span>
						</p>
						<p class="fragment" data-fragment-index="1">
							Easy to see the characteristic equation of both $A$ and $B$ is
              $$(2-\lambda)(1-\lambda)^2=0,$$ so $\lambda=2,1,1$.
						</p>
						
					</div>
				</div><br/><br/>
			</section>

			<section data-auto-animate>
				<h5>16.3.1 Example</h5>
				<div class="size-40" style="font-weight:bold">
					<div class="left-txt">
						<p>
							<span>
								Let $A=\left(\begin{array}{ccc}2&1&3\\0&1&0\\0&0&1\end{array}\right)$
                and $B=\left(\begin{array}{ccc}2&1&3\\0&1&1\\0&0&1\end{array}\right)$.
							</span>
              <span>
                Characteristic equation of both $A$ and $B$ is
                $(2-\lambda)(1-\lambda)^2=0,$ so $\lambda=2,1,1$.
              </span>
						</p>
						
						
					</div>
				</div>
        
        <div class="size-70">
					<div class="left-txt">
						<p>
							<span class="fragment" data-fragment-index="0">
								Note that both matrices have two ($n\lt 3$) distinct eigenvalues.
							</span>
						</p>
						<p class="fragment" data-fragment-index="1">
							For $A:$ We have that for $\lambda=2$
						</p>
						
					</div>
          <div>
            <p class="fragment" data-fragment-index="2">
              $\ds
              \left(A-\lambda I\right)\mathbf x
              $
              <span class="fragment" data-fragment-index="3">
                $=
                \left(
                \begin{array}{rrr}
                0   & 1 & 3 \\
                0 & -1 &0 \\
                0 & 0 & -1  \\
                \end{array}
                \right)
                \left(
                \begin{array}{c}
                x_1    \\
                x_2  \\
                x_3  \\
                \end{array}
                \right)
                
                $
              </span>
              <span class="fragment" data-fragment-index="4">
                $
                =\left(
                  \begin{array}{c}
                  0    \\
                  0  \\
                  0  \\
                  \end{array}
                  \right)
                $
              </span>
            </p>
          </div>
          <div>
            <p class="fragment" data-fragment-index="5">
              $\Ra$ $x_3 = x_2 = 0,$
              <span class="fragment" data-fragment-index="6">
                which means that $x_1$ is free variable.
              </span>
              

            </p>
            <p>
              <span class="fragment" data-fragment-index="7">
                Thus 
                $
                \left(
              \begin{array}{c}
              x_1    \\
              x_2  \\
              x_3  \\
              \end{array}
              \right)
              =\left(
                \begin{array}{c}
                x_1    \\
                0  \\
                0  \\
                \end{array}
                \right)
                $
              </span>
              <span class="fragment" data-fragment-index="8">
                $
                =x_1
                \left(
                  \begin{array}{c}
                  1    \\
                  0  \\
                  0  \\
                  \end{array}
                  \right).
                $
              </span>
              <span class="fragment" data-fragment-index="9">
                The eigenvector is 
                $\v_1 = 
                \left(
                  \begin{array}{c}
                  1    \\
                  0  \\
                  0  \\
                  \end{array}
                  \right).
                $
              </span>
            </p>
          </div>

				</div>
        <br/>
			</section>

			<section data-auto-animate>
				<h5>16.3.1 Example</h5>
				
        
        <div class="size-70">
					<div class="left-txt">
						<p>
							For $A:$ Now for $\lambda=1$
						</p>
						
					</div>
          <div>
            <p class="fragment" data-fragment-index="0">
              $\ds
              \left(A-\lambda I\right)\mathbf x=
              \left(
              \begin{array}{ccc}
              1   & 1 & 3 \\
              0 & 0 &0 \\
              0 & 0 & 0 \\
              \end{array}
              \right)
              \left(
              \begin{array}{c}
              x_1    \\
              x_2  \\
              x_3  \\
              \end{array}
              \right)
              =\left(
                \begin{array}{c}
                0    \\
                0  \\
                0  \\
                \end{array}
                \right)
              $
              <span class="fragment" data-fragment-index="1">
                $\;\Ra\;$ $\;x_1+x_2+3x_3=0.$
              </span>
            </p>
          </div>
          <div class="left-txt">
            
            <p>
              <span class="fragment" data-fragment-index="2">
                So $\;x_1=-x_2-3x_3$.
              </span>
              <span class="fragment" data-fragment-index="3">
                Thus
              </span>
              <span class="fragment" data-fragment-index="3">
                
                $\;
                \left(
              \begin{array}{c}
              x_1    \\
              x_2  \\
              x_3  \\
              \end{array}
              \right)
              =\left(
                \begin{array}{c}
                -x_2-3x_3   \\
                x_2  \\
                x_3  \\
                \end{array}
                \right)
                $
              </span>
              <span class="fragment" data-fragment-index="4">
                $
                =x_2
                \left(
                  \begin{array}{c}
                  -1    \\
                  1  \\
                  0  \\
                  \end{array}
                  \right)
                  +
                  x_3
                  \left(
                  \begin{array}{c}
                  -3    \\
                  0  \\
                  1  \\
                  \end{array}
                  \right).
                $
              </span>
              
            </p>
          </div>

          <div>
            <p>
              <span class="fragment" data-fragment-index="5">
                The eigenvectors are 
                $\v_2 = 
                \left(
                  \begin{array}{c}
                  -1    \\
                  1  \\
                  0  \\
                  \end{array}
                  \right)
                $
                and
                $\v_3 = 
                \left(
                  \begin{array}{c}
                  -3    \\
                  0  \\
                  1  \\
                  \end{array}
                  \right).
                $ 
              </span>
            </p>
          </div>

				</div>
        <br/>
			</section>

			<section data-auto-animate>
				<h5>16.3.1 Example</h5>
				<div class="size-40" style="font-weight:bold">
					<div>
						<p>
							<span>
								$A=\left(\begin{array}{ccc}2&1&3\\0&1&0\\0&0&1\end{array}\right)$
							</span>
             
						</p>
						
						
					</div>
				</div>
        
        <div class="size-70">
					<div class="left-txt">
						
						<p>
							
              <span  class="fragment" data-fragment-index="0">
                Therefore $A$ is diagonalisable, 
              </span>
              <span  class="fragment" data-fragment-index="1">
                since $A$ has three linearly
                independent vectors.
              </span>
						</p>
						
					</div>
          
          <div style="font-size:85%;margin-top:-30px">
            <table>

              <tr>
                
                <td>
                  <table style="border: 1px solid #ddd;">
                    <tr>
                      <th style="text-align:center;border: 1px solid #ddd;">Eigenvalue</th>
                      <th style="text-align:center;border: 1px solid #ddd;">Eigenvector</th>
                    </tr>
                    <tr>
                      <td style="text-align:center;border: 1px solid #ddd;">$\lambda=2$</td>
                      <td style="text-align:center;border: 1px solid #ddd;">
                        $\left(
                          \begin{array}{r}
                          1  \\
                          0 \\
                          0 \\
                          \end{array}
                          \right)$
                      </td>
                    </tr>
                    <tr>
                      <td style="text-align:center;border: 1px solid #ddd;">$\lambda=1$</td>
                      <td style="text-align:center;border: 1px solid #ddd;">
                        $\left(
                          \begin{array}{r}
                          -1  \\
                          1 \\
                          0 \\
                          \end{array}
                          \right)$
                      </td>
                    </tr>
                    <tr>
                      <td style="text-align:center;border: 1px solid #ddd;">$\lambda=1$</td>
                      <td style="text-align:center;border: 1px solid #ddd;">
                        $\left(
                          \begin{array}{r}
                          -3  \\
                          0 \\
                          1 \\
                          \end{array}
                          \right)$
                      </td>
                    </tr>
                  </table>
                </td>
               
              </tr>

            </table>
            
          </div>

				</div>
        <br/>
			</section>

      <section data-auto-animate>
				<h5>16.3.1 Example</h5>
				<div class="size-40" style="font-weight:bold">
					<div class="left-txt">
						<p>
							<span>
								Let $A=\left(\begin{array}{ccc}2&1&3\\0&1&0\\0&0&1\end{array}\right)$
                and $B=\left(\begin{array}{ccc}2&1&3\\0&1&1\\0&0&1\end{array}\right)$.
							</span>
              <span>
                Characteristic equation of both $A$ and $B$ is
                $(2-\lambda)(1-\lambda)^2=0,$ so $\lambda=2,1,1$.
              </span>
						</p>
						
						
					</div>
				</div>
        
        <div class="size-70">
					<div class="left-txt">
						<p>
							Now for $B:$ 
              <span class="fragment" data-fragment-index="0">
                We have that for $\lambda=2$
              </span>
						</p>
						
					</div>
          <div>
            <p class="fragment" data-fragment-index="2">
              $\ds
              \left(A-\lambda I\right)\mathbf x
              $
              <span class="fragment" data-fragment-index="3">
                $=
                \left(
                \begin{array}{rrr}
                0   & 1 & 3 \\
                0 & -1 & 1 \\
                0 & 0 & -1  \\
                \end{array}
                \right)
                \left(
                \begin{array}{c}
                x_1    \\
                x_2  \\
                x_3  \\
                \end{array}
                \right)
                
                $
              </span>
              <span class="fragment" data-fragment-index="4">
                $
                =\left(
                  \begin{array}{c}
                  0    \\
                  0  \\
                  0  \\
                  \end{array}
                  \right)
                $
              </span>
            </p>
          </div>
          <div>
            <p class="fragment" data-fragment-index="5">
              $\Ra$ $x_2 = x_3 = 0,$
              <span class="fragment" data-fragment-index="6">
                which means that $x_1$ is free variable.
              </span>
              

            </p>
            <p>
              <span class="fragment" data-fragment-index="7">
                Thus 
                $
                \left(
              \begin{array}{c}
              x_1    \\
              x_2  \\
              x_3  \\
              \end{array}
              \right)
              =\left(
                \begin{array}{c}
                x_1    \\
                0  \\
                0  \\
                \end{array}
                \right)
                $
              </span>
              <span class="fragment" data-fragment-index="8">
                $
                =x_1
                \left(
                  \begin{array}{c}
                  1    \\
                  0  \\
                  0  \\
                  \end{array}
                  \right).
                $
              </span>
              <span class="fragment" data-fragment-index="9">
                The eigenvector is 
                $\v_1 = 
                \left(
                  \begin{array}{c}
                  1    \\
                  0  \\
                  0  \\
                  \end{array}
                  \right).
                $
              </span>
            </p>
          </div>

				</div>
        <br/><br/>
			</section>
      <section data-auto-animate>
				<h5>16.3.1 Example</h5>
				
        
        <div class="size-70">
					<div class="left-txt">
						<p>
							Now for $B:$ 
              <span>
                On the other hand, for $\lambda=1$
              </span>
						</p>
						
					</div>
          <div>
            <p class="fragment" data-fragment-index="2">
              $\ds
              \left(A-\lambda I\right)\mathbf x
              $
              <span class="fragment" data-fragment-index="3">
                $=
                \left(
                \begin{array}{ccc}
                1   & 1 & 3 \\
                0 & 0 & 1 \\
                0 & 0 & 0  \\
                \end{array}
                \right)
                \left(
                \begin{array}{c}
                x_1    \\
                x_2  \\
                x_3  \\
                \end{array}
                \right)
                
                $
              </span>
              <span class="fragment" data-fragment-index="4">
                $
                =\left(
                  \begin{array}{c}
                  0    \\
                  0  \\
                  0  \\
                  \end{array}
                  \right)
                $
              </span>
            </p>
          </div>
          <div>
            <p class="fragment" data-fragment-index="5">
              $\Ra$ $x_3 = 0,$
              <span class="fragment" data-fragment-index="6">
                and then $x_1+x_2+ 3x_3=0.$
              </span>
            </p>
            <p>
              <span class="fragment" data-fragment-index="7">
                Thus 
                $
                \left(
              \begin{array}{c}
              x_1    \\
              x_2  \\
              x_3  \\
              \end{array}
              \right)
              =\left(
                \begin{array}{r}
                x_1    \\
                -x_1  \\
                0  \\
                \end{array}
                \right)
                $
              </span>
              <span class="fragment" data-fragment-index="8">
                $
                =x_1
                \left(
                  \begin{array}{r}
                  1    \\
                  -1  \\
                  0  \\
                  \end{array}
                  \right).
                $
              </span>
              <span class="fragment" data-fragment-index="9">
                The eigenvector is 
                $\v_2 = 
                \left(
                  \begin{array}{r}
                  1    \\
                  -1  \\
                  0  \\
                  \end{array}
                  \right).
                $
              </span>
            </p>
          </div>

				</div>
        <br/><br/>
			</section>

      <section data-auto-animate>
				<h5>16.3.1 Example</h5>
				<div class="size-40" style="font-weight:bold">
					<div>
						<p>
							<span>
                $B=\left(\begin{array}{ccc}2&1&3\\0&1&1\\0&0&1\end{array}\right)$.
							</span>
             
						</p>
						
						
					</div>
				</div>
        
        <div class="size-75">
					<div class="left-txt">
						<p>
							
              <span  class="fragment" data-fragment-index="0">
                Therefore $B$ is <strong>NOT diagonalisable</strong>, 
              </span>
              <span  class="fragment" data-fragment-index="1">
                since $B$ has only two linearly
                independent vectors.
              </span>
						</p>
						
					</div>
          
          <div  style="font-size:85%;margin-top:-25px">
            <table>

              <tr>
                
                <td>
                  <table style="border: 1px solid #ddd;">
                    <tr>
                      <th style="text-align:center;border: 1px solid #ddd;">Eigenvalue</th>
                      <th style="text-align:center;border: 1px solid #ddd;">Eigenvector</th>
                    </tr>
                    <tr>
                      <td style="text-align:center;border: 1px solid #ddd;">$\lambda=2$</td>
                      <td style="text-align:center;border: 1px solid #ddd;">
                        $\left(
                          \begin{array}{r}
                          1  \\
                          0 \\
                          0 \\
                          \end{array}
                          \right)$
                      </td>
                    </tr>
                    <tr>
                      <td style="text-align:center;border: 1px solid #ddd;">$\lambda=1$</td>
                      <td style="text-align:center;border: 1px solid #ddd;">
                        $\left(
                          \begin{array}{r}
                          1  \\
                          -1 \\
                          0 \\
                          \end{array}
                          \right)$
                      </td>
                    </tr>
                    
                  </table>
                </td>
               
              </tr>

            </table>
            
          </div>

				</div>
        <br/><br/>
			</section>

		</section>

		<section>
 
			<section data-auto-animate>
				<h4>16.4 Algebraic and geometric multiplicity</h4>
				<div class="size-75">
					<div class="left-txt">
						<p>
							<span class="fragment" data-fragment-index="0">
								If we are only interested in finding out 
								whether or not a matrix is
								diagonalisable,
							</span>
							<span class="fragment" data-fragment-index="1">
								then we need to know the dimension of each eigenspace.
								There is one theorem (which we will not prove!) that states:
							</span>
						</p>
						<p class="fragment" data-fragment-index="2">
							If $\lambda_i$ is an eigenvalue, then the 
							dimension of the corresponding
							eigenspace cannot be greater than the number 
							of times $(\lambda-\lambda_i)$
							appears as a factor in the characteristic polynomial.
						</p>
					</div>
				</div>
				<br/><br/><br/>
			</section>

			<section data-auto-animate>
				<h4>16.4 Algebraic and geometric multiplicity</h4>
				<div class="size-75">
					<div class="left-txt">
						<p>
							We often use the following terminology:
							
						</p>
						<ul style="line-height:50px">
							<li class="fragment" data-fragment-index="0">
								The <em>geometric multiplicity</em> of the eigenvalue $\lambda_i$ is the dimension of the
								eigenspace corresponding to $\lambda_i$.
							</li>
							<li class="fragment" data-fragment-index="1">
								The <em>algebraic multiplicity</em> of the eigenvalue 
								$\lambda_i$ is the number 
								of times $(\lambda-\lambda_i)$ appears as 
								a factor in the characteristic polynomial.
							</li>
						</ul>
						<p class="fragment" data-fragment-index="2">
							The main result is the following:
						</p>
						<div id="theorem" class="fragment" data-fragment-index="2">
							<p>
							A square matrix is diagonalisable if and 
							only if the geometric and algebraic
							multiplicities are equal for every eigenvalue.
							</p>
						</div>
					</div>
				</div>
				<br/>
			</section>

		</section>

		<section>
 
			<section data-auto-animate>
				<h4>16.5 Applications of diagonalisability</h4>
				<div class="size-75">
					<div class="left-txt">
						<p class="fragment" data-fragment-index="0">
							<strong>16.5.1 Systems of differential equations</strong>
						</p>
						<p>
							
							<span class="fragment" data-fragment-index="1">
								For a system of coupled differential equations which can be written 
                in matrix form as 
                $$
                \dot{\mathbf x}=A{\mathbf x} 
                $$
                (where ${\mathbf x}=(x_1,\dots,x_n)^T$,
                $\dot{\mathbf x}=(\dot x_1,\dots,\dot x_n)^T$),
							</span>
							<span class="fragment" data-fragment-index="2">
                if $A$ can be diagonalised, say 
                $P^{-1}AP=D$ with $D$ diagonal,
							</span>
							<span class="fragment" data-fragment-index="3">
								then make the substitution ${\mathbf x}=P{\mathbf y}$.
							</span>
							<span class="fragment" data-fragment-index="4">
								This yields
                $$
                \dot{\mathbf y}=D{\mathbf y} 
                $$
                which is easily solved.
							</span>
						</p>
					</div>
				</div>
				<br/>
			</section>

			<section data-auto-animate>
				<h4 style="font-size:85%">16.5 Applications of diagonalisability</h4>
				<div class="size-40">
					<div class="left-txt">
						<p>
							<strong>16.5.1 Systems of differential equations</strong>
						</p>
						<p>
							
							<span>
								For a system of coupled differential equations which can be written 
                in matrix form as 
                $
                \dot{\mathbf x}=A{\mathbf x} 
                $
                (where ${\mathbf x}=(x_1,\dots,x_n)^T$,
                $\dot{\mathbf x}=(\dot x_1,\dots,\dot x_n)^T$),
							</span>
							<span>
                if $A$ can be diagonalised, say 
                $P^{-1}AP=D$ with $D$ diagonal,
							</span>
							<span>
								then make the substitution ${\mathbf x}=P{\mathbf y}$.
							</span>
							<span>
								This yields
                $
                \dot{\mathbf y}=D{\mathbf y} 
                $
                which is easily solved.
							</span>
						</p>
					</div>
				</div>
				<div class="size-75">
					<div class="left-txt">
						<p>
							
							<span class="fragment" data-fragment-index="0">
								For example, consider the coupled system of ODEs:
                \[
                \left\{
                  \begin{array}{rcrcr}
                  \dot x_1 & = & x_1  & + & 2x_2\\ 
                  \dot x_2 & = & 2x_1 & + & x_2\\ 
                  \end{array}
                \right.
                \]
							</span>
							<span class="fragment" data-fragment-index="1">
                Write 
                $
                \left(
                  \begin{array}{r}
                  \dot x_1 \\ 
                  \dot x_2 \\ 
                  \end{array}
                \right)
                =
                \left(
                  \begin{array}{cc}
                  1 & 2\\ 
                  2 & 1\\ 
                  \end{array}
                \right)
                \left(
                  \begin{array}{r}
                   x_1 \\ 
                   x_2 \\ 
                  \end{array}
                \right)\;
                $
							</span>
							<span class="fragment" data-fragment-index="2">
								or
							</span>
							<span class="fragment" data-fragment-index="2">
								$\; \dot{\mathbf x} = A \mathbf x.$ $\quad (\star)$
							</span>
						</p>
            <p class="fragment" data-fragment-index="3">
              Is $A$ diagonalizable? ðŸ¤”
              <span class="fragment" data-fragment-index="4">
                The answer is "Yes".
              </span>
              <span class="fragment" data-fragment-index="5">
                $\;\Ra \; P^{-1}A P = D.$
              </span>
            </p>
            
					</div>
				</div>
				<br/><br/>
			</section>

			<section data-auto-animate>
				<h4 style="font-size:85%">16.5 Applications of diagonalisability</h4>
				<div class="size-40">
					<div class="left-txt">
						<p>
							<strong>16.5.1 Systems of differential equations</strong>
						</p>
						<p>
							
							<span>
								For a system of coupled differential equations which can be written 
                in matrix form as 
                $
                \dot{\mathbf x}=A{\mathbf x} 
                $
                (where ${\mathbf x}=(x_1,\dots,x_n)^T$,
                $\dot{\mathbf x}=(\dot x_1,\dots,\dot x_n)^T$),
							</span>
							<span>
                if $A$ can be diagonalised, say 
                $P^{-1}AP=D$ with $D$ diagonal,
							</span>
							<span>
								then make the substitution ${\mathbf x}=P{\mathbf y}$.
							</span>
							<span>
								This yields
                $
                \dot{\mathbf y}=D{\mathbf y} 
                $
                which is easily solved.
							</span>
						</p>
					</div>
				</div>
				<div class="size-75">
					<div class="left-txt">
						<p>
							<span>
                Write 
                $
                \left(
                  \begin{array}{r}
                  \dot x_1 \\ 
                  \dot x_2 \\ 
                  \end{array}
                \right)
                =
                \left(
                  \begin{array}{cc}
                  1 & 2\\ 
                  2 & 1\\ 
                  \end{array}
                \right)
                \left(
                  \begin{array}{r}
                   x_1 \\ 
                   x_2 \\ 
                  \end{array}
                \right)\;
                $
							</span>
							<span>
								or
							</span>
							<span>
								$\; \dot{\mathbf x} = A \mathbf x.$ $\quad (\star)$
							</span>
						</p>
            <p>
              Is $A$ diagonalizable? ðŸ¤”
              <span>
                The answer is "Yes".
              </span>
              <span>
                $\;\Ra \; P^{-1}A P = D.$
              </span>
            </p>
            <p class="fragment" data-fragment-index="0">
              From $\;(\star)\;\Ra$ $\;P^{-1}\dot{\mathbf x}$
              <span class="fragment" data-fragment-index="1">
                $= P^{-1}A \mathbf x$
              </span>
              <span class="fragment" data-fragment-index="2">
                $= P^{-1}A I {\mathbf x}$
              </span>
              <span class="fragment" data-fragment-index="3">
                $= P^{-1}A P P^{-1}{\mathbf x}$
              </span>
              <span class="fragment" data-fragment-index="4">
                $= D P^{-1}{\mathbf x}.$
              </span>
              <span class="fragment" data-fragment-index="5">
                Thus
                \[
                \frac{d}{dt}\left(P^{-1}\mathbf x \right)= D \left(P^{-1}\mathbf x\right)\qquad (\star \star)
                \]
              </span>
            </p>
					</div>
         
				</div>
				<br/><br/>
			</section>

			<section data-auto-animate>
				<h4 style="font-size:85%">16.5 Applications of diagonalisability</h4>
				<div class="size-40">
					<div class="left-txt">
						<p>
							<strong>16.5.1 Systems of differential equations</strong>
						</p>
						<p>
							
							<span>
								For a system of coupled differential equations which can be written 
                in matrix form as 
                $
                \dot{\mathbf x}=A{\mathbf x} 
                $
                (where ${\mathbf x}=(x_1,\dots,x_n)^T$,
                $\dot{\mathbf x}=(\dot x_1,\dots,\dot x_n)^T$),
							</span>
							<span>
                if $A$ can be diagonalised, say 
                $P^{-1}AP=D$ with $D$ diagonal,
							</span>
							<span>
								then make the substitution ${\mathbf x}=P{\mathbf y}$.
							</span>
							<span>
								This yields
                $
                \dot{\mathbf y}=D{\mathbf y} 
                $
                which is easily solved.
							</span>
						</p>
					</div>
				</div>
				<div class="size-75" style="margin-top:-20px">
          <div>
            <p>
              <span style="font-size:80%">
                $
                \dfrac{d}{dt}\left(P^{-1}\mathbf x \right) = D \left(P^{-1}\mathbf x\right)\qquad (\star \star)
                $
              </span>
            </p>
          </div>
					<div class="left-txt">
            
            
            <p class="fragment" data-fragment-index="0">
              Introducing the expression
              $
              \mathbf y(t) =  
              \left(
                \begin{array}{r}
                y_1(t) \\ 
                y_2(t) \\ 
                \end{array}
              \right)
              = P^{-1}\mathbf x,\,
              $
              <span class="fragment" data-fragment-index="1">
                implies that
              </span>
            </p>
					</div>
          <div>
            <p class="fragment" data-fragment-index="1">
              $\dot{\mathbf y} = D \mathbf y\;$ (from $\;(\star \star)$)
              <span class="fragment" data-fragment-index="2">
                $\;\Ra\; 
                \left(
                \begin{array}{r}
                \dot y_1(t) \\ 
                \dot y_2(t) \\ 
                \end{array}
              \right)
              = 
              \left(
                \begin{array}{cc}
                \lambda_1 & 0 \\ 
                0 & \lambda_2\\ 
                \end{array}
              \right)
              \left(
                \begin{array}{r}
                 y_1(t) \\ 
                 y_2(t) \\ 
                \end{array}
              \right)
                $
              </span>
            </p>
            <p class="fragment" data-fragment-index="3">
              $\Ra\; \dot y_1 = \lambda_1y_1\;$ and $\; \dot y_2 = \lambda_2y_2.\qquad $
            </p>
          </div>
         
				</div>
				<br/><br/><br/>
			</section>
			<section data-auto-animate>
				<h4 style="font-size:85%">16.5 Applications of diagonalisability</h4>
				<div class="size-40">
					<div class="left-txt">
						<p>
							<strong>16.5.1 Systems of differential equations</strong>
						</p>
						<p>
							
							<span>
								For a system of coupled differential equations which can be written 
                in matrix form as 
                $
                \dot{\mathbf x}=A{\mathbf x} 
                $
                (where ${\mathbf x}=(x_1,\dots,x_n)^T$,
                $\dot{\mathbf x}=(\dot x_1,\dots,\dot x_n)^T$),
							</span>
							<span>
                if $A$ can be diagonalised, say 
                $P^{-1}AP=D$ with $D$ diagonal,
							</span>
							<span>
								then make the substitution ${\mathbf x}=P{\mathbf y}$.
							</span>
							<span>
								This yields
                $
                \dot{\mathbf y}=D{\mathbf y} 
                $
                which is easily solved.
							</span>
						</p>
					</div>
				</div>
				<div class="size-75">
          
					
          <div>
            <p>
              $\dot{\mathbf y} = D \mathbf y\;$ (from $\;(\star \star)$)
              <span>
                $\;\Ra\; 
                \left(
                \begin{array}{r}
                \dot y_1(t) \\ 
                \dot y_2(t) \\ 
                \end{array}
              \right)
              = 
              \left(
                \begin{array}{cc}
                \lambda_1 & 0 \\ 
                0 & \lambda_2\\ 
                \end{array}
              \right)
              \left(
                \begin{array}{r}
                \dot y_1(t) \\ 
                \dot y_2(t) \\ 
                \end{array}
              \right)
                $
              </span>
            </p>
            <p>
              $\Ra\; \dot y_1 = \lambda_1y_1\;$ and $\; \dot y_2 = \lambda_2y_2.\qquad$
            </p>
          </div>

          <div class="left-txt">
            <p>
              Finally, solve for $\,y_1$ and $y_2,\,$
              <span class="fragment" data-fragment-index="0">
                then substitute into $\,\mathbf x = P\mathbf y\,$ to get $\,x_1, x_2.$
              </span>
            </p>
          </div>
         
				</div>
				<br/><br/><br/><br/>
			</section>

		</section>

		<section>
 
			<section data-auto-animate>
				<h5>16.5.2 Matrix powers</h5>
				<div class="size-75">
					<div class="left-txt">
						<p>
							If $A$ is diagonalisable, say $P^{-1}AP=D$ with $D$ diagonal,
              <span class="fragment" data-fragment-index="0">
                then
                $$
                A^n=PD^nP^{-1}.
                $$
                This gives an easy way to calculate $A^n$.
              </span>
						</p>
            <p class="fragment" data-fragment-index="1">
              From $A= PDP^{-1}$
              <span>
                we have that
              </span>
            </p>

					</div>
          <div>
            <p class="fragment" data-fragment-index="2">
              $A^n$
              <span class="fragment" data-fragment-index="3">
                $=\underbrace{PDP^{-1} P D P^{-1} \cdots P D P^{-1}}_{n-\text{times}}$
              </span>
              <span class="fragment" data-fragment-index="4">
                $=P D^n P^{-1},$
              </span>
              
            </p>
            
          </div>
          <div>
            <p>
              <span class="fragment" data-fragment-index="5">
                where
              </span>
              <span class="fragment" data-fragment-index="5">
                $\;D^n $
              </span> 
              <span class="fragment" data-fragment-index="6">
                $ = 
                \left(
                \begin{array}{ccc}
                \lambda_1 &  \ldots  & 0 \\
                \vdots &  \ddots  & \vdots \\
                0 &  \ldots  &  \lambda_n\\
                \end{array}
                \right)^n$
              </span> 
              <span class="fragment" data-fragment-index="7">
                $=
                \left(
                \begin{array}{ccc}
                \lambda_1^n &  \ldots  & 0 \\
                \vdots &  \ddots  & \vdots \\
                0 &  \ldots  &  \lambda_n^n\\
                \end{array}
                \right).$
              </span>
              
            </p>
          </div>
				</div>
        <br/><br/>
			</section>

			<section data-auto-animate>
				<h5>16.5.3 Linear systems</h5>
				<div class="size-85">
					<div class="left-txt">
						<p>
							What can we say about the linear system 
							(corresponding to a square matrix $A$) 
              
						</p>
            <p style="margin-top:-30px">
              $$
              A{\mathbf x} = {\mathbf b},
              $$
            </p>
            <p style="margin-top:-20px">
              if we know how to diagonalise $A$?
            </p>

            <p class="fragment" data-fragment-index="0">
              Multiply $A{\mathbf x} = {\mathbf b}$ by $P^{-1}$ from left on both sides.
              <span class="fragment" data-fragment-index="1">
                Then we get
              </span>
            </p>
					</div>
          <div>
            <p class="fragment" data-fragment-index="1">
              $P^{-1}A \mathbf x $
              <span class="fragment" data-fragment-index="2">
                $= P^{-1}A I\mathbf x$
              </span>
              <span class="fragment" data-fragment-index="3">
                $= P^{-1}A P P^{-1}\mathbf x$
              </span>
              <span class="fragment" data-fragment-index="4">
                $= P^{-1} \mathbf b.\;$
              </span><br/>
              <span class="fragment" data-fragment-index="5">
                Then $\;D\left(P^{-1} \mathbf x\right) = P^{-1} \mathbf b.$
              </span>
            </p>
          </div>

          <div class="left-txt">
            <p class="fragment" data-fragment-index="6">
              Set $\mathbf y = P^{-1}\mathbf x$,
              <span class="fragment" data-fragment-index="7">
                then $D\mathbf y = P^{-1} \mathbf b.$
              </span>
              <span class="fragment" data-fragment-index="8">
                ðŸ‘ˆ This is a decoupled system!
              </span>
              <span class="fragment" data-fragment-index="10">
              Finally, solve for $\mathbf y $ and then $\mathbf x = P \mathbf y.$
              </span>
            </p>
           
          </div>
				</div>
        <br/><br/> 
			</section>
			

		</section>

        <section>
          <h4>Credits</h4>
          <div include-html="creditsb.html"></div>
        </section>

        <!-- Ends sections -->
      </div>
    </div>

    <script src="revealjs/dist/reveal.js"></script>
    <script src="revealjs/plugin/math/math.js"></script>
    <script src="revealjs/plugin/highlight/highlight.js"></script>
    <script src="revealjs/plugin/zoom/zoom.js"></script>
    <script src="revealjs/plugin/search/search.js"></script>
    <script src="revealjs/third-party-plugin/chalkboard/plugin.js"></script>
    <script src="revealjs/third-party-plugin/customcontrols/plugin.js"></script>
    <script src="revealjs/third-party-plugin/menu/menu.js"></script>
    <script src="mySetup/setup.js"></script>
  
    <script>
      includeHTML();
    </script>
  </body>
</html>
